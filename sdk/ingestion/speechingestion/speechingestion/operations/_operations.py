# pylint: disable=too-many-lines,too-many-statements
# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) Python Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------
from io import IOBase
import json
import sys
from typing import Any, Callable, Dict, IO, Iterable, List, Optional, TypeVar, Union, overload
import urllib.parse

from azure.core.exceptions import (
    ClientAuthenticationError,
    HttpResponseError,
    ResourceExistsError,
    ResourceNotFoundError,
    ResourceNotModifiedError,
    map_error,
)
from azure.core.paging import ItemPaged
from azure.core.pipeline import PipelineResponse
from azure.core.rest import HttpRequest, HttpResponse
from azure.core.tracing.decorator import distributed_trace
from azure.core.utils import case_insensitive_dict

from .. import models as _models
from .._model_base import SdkJSONEncoder, _deserialize
from .._serialization import Serializer

if sys.version_info >= (3, 9):
    from collections.abc import MutableMapping
else:
    from typing import MutableMapping  # type: ignore  # pylint: disable=ungrouped-imports
JSON = MutableMapping[str, Any]  # pylint: disable=unsubscriptable-object
T = TypeVar("T")
ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]

_SERIALIZER = Serializer()
_SERIALIZER.client_side_validation = False


def build_registrations_get_registration_request(  # pylint: disable=name-too-long
    name: str, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    api_version: str = kwargs.pop("api_version", _params.pop("api-version", "2024-05-15-preview"))
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/registrations/{name}"
    path_format_arguments = {
        "name": _SERIALIZER.url("name", name, "str"),
    }

    _url: str = _url.format(**path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_registrations_create_or_replace_registration_request(  # pylint: disable=name-too-long
    name: str, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    api_version: str = kwargs.pop("api_version", _params.pop("api-version", "2024-05-15-preview"))
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/registrations/{name}"
    path_format_arguments = {
        "name": _SERIALIZER.url("name", name, "str"),
    }

    _url: str = _url.format(**path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")

    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)


def build_registrations_delete_registration_request(  # pylint: disable=name-too-long
    name: str, **kwargs: Any
) -> HttpRequest:
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    api_version: str = kwargs.pop("api_version", _params.pop("api-version", "2024-05-15-preview"))
    # Construct URL
    _url = "/registrations/{name}"
    path_format_arguments = {
        "name": _SERIALIZER.url("name", name, "str"),
    }

    _url: str = _url.format(**path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    return HttpRequest(method="DELETE", url=_url, params=_params, **kwargs)


def build_registrations_list_registrations_request(**kwargs: Any) -> HttpRequest:  # pylint: disable=name-too-long
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    api_version: str = kwargs.pop("api_version", _params.pop("api-version", "2024-05-15-preview"))
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/registrations"

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


class RegistrationsOperations:
    """
    .. warning::
        **DO NOT** instantiate this class directly.

        Instead, you should access the following operations through
        :class:`~speechingestion.IngestionClient`'s
        :attr:`registrations` attribute.
    """

    def __init__(self, *args, **kwargs):
        input_args = list(args)
        self._client = input_args.pop(0) if input_args else kwargs.pop("client")
        self._config = input_args.pop(0) if input_args else kwargs.pop("config")
        self._serialize = input_args.pop(0) if input_args else kwargs.pop("serializer")
        self._deserialize = input_args.pop(0) if input_args else kwargs.pop("deserializer")

    @distributed_trace
    def get_registration(self, name: str, **kwargs: Any) -> _models.Registration:
        # pylint: disable=line-too-long
        """Fetch a Registration by name.

        :param name: The unique name of the registration resource. Required.
        :type name: str
        :return: Registration. The Registration is compatible with MutableMapping
        :rtype: ~speechingestion.models.Registration
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # response body for status code(s): 200
                response == {
                    "batchTranscriptionModel": {
                        "customDomain": "str",  # Custom domain name for batch transcription.
                          Required.
                        "locale": "str",  # Optional. The expected locale of the audio data
                          to transcribe. For example, 'en-US', 'fr-FR', 'zh-CN', etc. For a full list
                          of supported locales, see `Supported languages and regions
                          <https://learn.microsoft.com/azure/ai-services/speech-service/language-support?tabs=stt>`_.
                        "modelX": {
                            "self": "str"  # self. Required.
                        },
                        "transcriptionProperties": {
                            "channels": [
                                0  # Optional. An array of channel numbers to
                                  process. Channels 0 and 1 are transcribed by default.
                            ],
                            "diarization": {
                                "speakers": {
                                    "maxCount": 0,  # Optional. Maximum count of
                                      speakers.
                                    "minCount": 0  # Optional. Minimum count of
                                      speakers.
                                }
                            },
                            "diarizationEnabled": bool,  # Optional. Specifies that the
                              Speech service should attempt diarization analysis on the input, which is
                              expected to be a mono channel that contains two voices. The default value
                              is false.
                            "displayFormWordLevelTimestampsEnabled": bool,  # Optional.
                              Specifies whether to include word-level timestamps on the display form of
                              the transcription results. The results are returned in the displayWords
                              property of the transcription file. The default value is false.
                            "languageIdentification": {
                                "candidateLocales": [
                                    "str"  # candidateLocales. Required.
                                ],
                                "mode": "str",  # mode. Required.
                                "speechModelMapping": {
                                    "str": {
                                        "self": "str"  # self. Required.
                                    }
                                }
                            },
                            "profanityFilterMode": "str",  # Optional. Specifies how to
                              handle profanity in recognition results. Accepted values are None to
                              disable profanity filtering, Masked to replace profanity with asterisks,
                              Removed to remove all profanity from the result, or Tags to add profanity
                              tags. The default value is Masked.
                            "punctuationMode": "str",  # Optional. Specifies how to
                              handle punctuation in recognition results. Accepted values are None to
                              disable punctuation, Dictated to imply explicit (spoken) punctuation,
                              Automatic to let the decoder deal with punctuation, or
                              DictatedAndAutomatic to use dictated and automatic punctuation. The
                              default value is DictatedAndAutomatic.
                            "wordLevelTimestampsEnabled": bool  # Optional. Specifies if
                              word level timestamps should be included in the output. The default value
                              is false.
                        }
                    },
                    "name": "str",  # The unique name of the registration resource. Required.
                    "processingModel": {
                        "deliveryMode": "str",  # deliveryMode. Required.
                        "subjectEndsWith": "str",  # Optional. Extensions of input files.
                        "systemTopicResourceId": "str"  # Optional. ResourceId for System
                          Topic.
                    },
                    "statusModel": {
                        "code": "str",  # Status code. Required.
                        "message": "str"  # Optional. Message.
                    },
                    "storageModel": {
                        "blobStorageEndpoint": "str",  # The Uri of the blob storage account
                          in the form of 'https://:code:`<accountname>`.blob.core.windows.net'.
                          Required.
                        "errorOutputContainerName": "str",  # The name of the container that
                          saves the error messages during processing. Required.
                        "inputContainerName": "str",  # The name of the container that holds
                          the audio files to be processed. Required.
                        "outputContainerName": "str",  # The name of the container that
                          stores the transcription and analytics results. Required.
                        "processedContainerName": "str"  # The name of the container that
                          archives the audio files that have been transcribed. Required.
                    },
                    "analyticsModel": {
                        "endpoint": "str"  # The analytics endpoint to call. Required.
                    }
                }
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.Registration] = kwargs.pop("cls", None)

        _request = build_registrations_get_registration_request(
            name=name,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        _request.url = self._client.format_url(_request.url)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models.Registration, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @overload
    def create_or_replace_registration(
        self, name: str, resource: _models.Registration, *, content_type: str = "application/json", **kwargs: Any
    ) -> _models.Registration:
        # pylint: disable=line-too-long
        """Creates or replaces a Registration.

        :param name: The unique name of the registration resource. Required.
        :type name: str
        :param resource: The resource instance. Required.
        :type resource: ~speechingestion.models.Registration
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: Registration. The Registration is compatible with MutableMapping
        :rtype: ~speechingestion.models.Registration
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # JSON input template you can fill out and use as your body input.
                resource = {
                    "batchTranscriptionModel": {
                        "customDomain": "str",  # Custom domain name for batch transcription.
                          Required.
                        "locale": "str",  # Optional. The expected locale of the audio data
                          to transcribe. For example, 'en-US', 'fr-FR', 'zh-CN', etc. For a full list
                          of supported locales, see `Supported languages and regions
                          <https://learn.microsoft.com/azure/ai-services/speech-service/language-support?tabs=stt>`_.
                        "modelX": {
                            "self": "str"  # self. Required.
                        },
                        "transcriptionProperties": {
                            "channels": [
                                0  # Optional. An array of channel numbers to
                                  process. Channels 0 and 1 are transcribed by default.
                            ],
                            "diarization": {
                                "speakers": {
                                    "maxCount": 0,  # Optional. Maximum count of
                                      speakers.
                                    "minCount": 0  # Optional. Minimum count of
                                      speakers.
                                }
                            },
                            "diarizationEnabled": bool,  # Optional. Specifies that the
                              Speech service should attempt diarization analysis on the input, which is
                              expected to be a mono channel that contains two voices. The default value
                              is false.
                            "displayFormWordLevelTimestampsEnabled": bool,  # Optional.
                              Specifies whether to include word-level timestamps on the display form of
                              the transcription results. The results are returned in the displayWords
                              property of the transcription file. The default value is false.
                            "languageIdentification": {
                                "candidateLocales": [
                                    "str"  # candidateLocales. Required.
                                ],
                                "mode": "str",  # mode. Required.
                                "speechModelMapping": {
                                    "str": {
                                        "self": "str"  # self. Required.
                                    }
                                }
                            },
                            "profanityFilterMode": "str",  # Optional. Specifies how to
                              handle profanity in recognition results. Accepted values are None to
                              disable profanity filtering, Masked to replace profanity with asterisks,
                              Removed to remove all profanity from the result, or Tags to add profanity
                              tags. The default value is Masked.
                            "punctuationMode": "str",  # Optional. Specifies how to
                              handle punctuation in recognition results. Accepted values are None to
                              disable punctuation, Dictated to imply explicit (spoken) punctuation,
                              Automatic to let the decoder deal with punctuation, or
                              DictatedAndAutomatic to use dictated and automatic punctuation. The
                              default value is DictatedAndAutomatic.
                            "wordLevelTimestampsEnabled": bool  # Optional. Specifies if
                              word level timestamps should be included in the output. The default value
                              is false.
                        }
                    },
                    "name": "str",  # The unique name of the registration resource. Required.
                    "processingModel": {
                        "deliveryMode": "str",  # deliveryMode. Required.
                        "subjectEndsWith": "str",  # Optional. Extensions of input files.
                        "systemTopicResourceId": "str"  # Optional. ResourceId for System
                          Topic.
                    },
                    "statusModel": {
                        "code": "str",  # Status code. Required.
                        "message": "str"  # Optional. Message.
                    },
                    "storageModel": {
                        "blobStorageEndpoint": "str",  # The Uri of the blob storage account
                          in the form of 'https://:code:`<accountname>`.blob.core.windows.net'.
                          Required.
                        "errorOutputContainerName": "str",  # The name of the container that
                          saves the error messages during processing. Required.
                        "inputContainerName": "str",  # The name of the container that holds
                          the audio files to be processed. Required.
                        "outputContainerName": "str",  # The name of the container that
                          stores the transcription and analytics results. Required.
                        "processedContainerName": "str"  # The name of the container that
                          archives the audio files that have been transcribed. Required.
                    },
                    "analyticsModel": {
                        "endpoint": "str"  # The analytics endpoint to call. Required.
                    }
                }

                # response body for status code(s): 201, 200
                response == {
                    "batchTranscriptionModel": {
                        "customDomain": "str",  # Custom domain name for batch transcription.
                          Required.
                        "locale": "str",  # Optional. The expected locale of the audio data
                          to transcribe. For example, 'en-US', 'fr-FR', 'zh-CN', etc. For a full list
                          of supported locales, see `Supported languages and regions
                          <https://learn.microsoft.com/azure/ai-services/speech-service/language-support?tabs=stt>`_.
                        "modelX": {
                            "self": "str"  # self. Required.
                        },
                        "transcriptionProperties": {
                            "channels": [
                                0  # Optional. An array of channel numbers to
                                  process. Channels 0 and 1 are transcribed by default.
                            ],
                            "diarization": {
                                "speakers": {
                                    "maxCount": 0,  # Optional. Maximum count of
                                      speakers.
                                    "minCount": 0  # Optional. Minimum count of
                                      speakers.
                                }
                            },
                            "diarizationEnabled": bool,  # Optional. Specifies that the
                              Speech service should attempt diarization analysis on the input, which is
                              expected to be a mono channel that contains two voices. The default value
                              is false.
                            "displayFormWordLevelTimestampsEnabled": bool,  # Optional.
                              Specifies whether to include word-level timestamps on the display form of
                              the transcription results. The results are returned in the displayWords
                              property of the transcription file. The default value is false.
                            "languageIdentification": {
                                "candidateLocales": [
                                    "str"  # candidateLocales. Required.
                                ],
                                "mode": "str",  # mode. Required.
                                "speechModelMapping": {
                                    "str": {
                                        "self": "str"  # self. Required.
                                    }
                                }
                            },
                            "profanityFilterMode": "str",  # Optional. Specifies how to
                              handle profanity in recognition results. Accepted values are None to
                              disable profanity filtering, Masked to replace profanity with asterisks,
                              Removed to remove all profanity from the result, or Tags to add profanity
                              tags. The default value is Masked.
                            "punctuationMode": "str",  # Optional. Specifies how to
                              handle punctuation in recognition results. Accepted values are None to
                              disable punctuation, Dictated to imply explicit (spoken) punctuation,
                              Automatic to let the decoder deal with punctuation, or
                              DictatedAndAutomatic to use dictated and automatic punctuation. The
                              default value is DictatedAndAutomatic.
                            "wordLevelTimestampsEnabled": bool  # Optional. Specifies if
                              word level timestamps should be included in the output. The default value
                              is false.
                        }
                    },
                    "name": "str",  # The unique name of the registration resource. Required.
                    "processingModel": {
                        "deliveryMode": "str",  # deliveryMode. Required.
                        "subjectEndsWith": "str",  # Optional. Extensions of input files.
                        "systemTopicResourceId": "str"  # Optional. ResourceId for System
                          Topic.
                    },
                    "statusModel": {
                        "code": "str",  # Status code. Required.
                        "message": "str"  # Optional. Message.
                    },
                    "storageModel": {
                        "blobStorageEndpoint": "str",  # The Uri of the blob storage account
                          in the form of 'https://:code:`<accountname>`.blob.core.windows.net'.
                          Required.
                        "errorOutputContainerName": "str",  # The name of the container that
                          saves the error messages during processing. Required.
                        "inputContainerName": "str",  # The name of the container that holds
                          the audio files to be processed. Required.
                        "outputContainerName": "str",  # The name of the container that
                          stores the transcription and analytics results. Required.
                        "processedContainerName": "str"  # The name of the container that
                          archives the audio files that have been transcribed. Required.
                    },
                    "analyticsModel": {
                        "endpoint": "str"  # The analytics endpoint to call. Required.
                    }
                }
        """

    @overload
    def create_or_replace_registration(
        self, name: str, resource: JSON, *, content_type: str = "application/json", **kwargs: Any
    ) -> _models.Registration:
        # pylint: disable=line-too-long
        """Creates or replaces a Registration.

        :param name: The unique name of the registration resource. Required.
        :type name: str
        :param resource: The resource instance. Required.
        :type resource: JSON
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: Registration. The Registration is compatible with MutableMapping
        :rtype: ~speechingestion.models.Registration
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # response body for status code(s): 201, 200
                response == {
                    "batchTranscriptionModel": {
                        "customDomain": "str",  # Custom domain name for batch transcription.
                          Required.
                        "locale": "str",  # Optional. The expected locale of the audio data
                          to transcribe. For example, 'en-US', 'fr-FR', 'zh-CN', etc. For a full list
                          of supported locales, see `Supported languages and regions
                          <https://learn.microsoft.com/azure/ai-services/speech-service/language-support?tabs=stt>`_.
                        "modelX": {
                            "self": "str"  # self. Required.
                        },
                        "transcriptionProperties": {
                            "channels": [
                                0  # Optional. An array of channel numbers to
                                  process. Channels 0 and 1 are transcribed by default.
                            ],
                            "diarization": {
                                "speakers": {
                                    "maxCount": 0,  # Optional. Maximum count of
                                      speakers.
                                    "minCount": 0  # Optional. Minimum count of
                                      speakers.
                                }
                            },
                            "diarizationEnabled": bool,  # Optional. Specifies that the
                              Speech service should attempt diarization analysis on the input, which is
                              expected to be a mono channel that contains two voices. The default value
                              is false.
                            "displayFormWordLevelTimestampsEnabled": bool,  # Optional.
                              Specifies whether to include word-level timestamps on the display form of
                              the transcription results. The results are returned in the displayWords
                              property of the transcription file. The default value is false.
                            "languageIdentification": {
                                "candidateLocales": [
                                    "str"  # candidateLocales. Required.
                                ],
                                "mode": "str",  # mode. Required.
                                "speechModelMapping": {
                                    "str": {
                                        "self": "str"  # self. Required.
                                    }
                                }
                            },
                            "profanityFilterMode": "str",  # Optional. Specifies how to
                              handle profanity in recognition results. Accepted values are None to
                              disable profanity filtering, Masked to replace profanity with asterisks,
                              Removed to remove all profanity from the result, or Tags to add profanity
                              tags. The default value is Masked.
                            "punctuationMode": "str",  # Optional. Specifies how to
                              handle punctuation in recognition results. Accepted values are None to
                              disable punctuation, Dictated to imply explicit (spoken) punctuation,
                              Automatic to let the decoder deal with punctuation, or
                              DictatedAndAutomatic to use dictated and automatic punctuation. The
                              default value is DictatedAndAutomatic.
                            "wordLevelTimestampsEnabled": bool  # Optional. Specifies if
                              word level timestamps should be included in the output. The default value
                              is false.
                        }
                    },
                    "name": "str",  # The unique name of the registration resource. Required.
                    "processingModel": {
                        "deliveryMode": "str",  # deliveryMode. Required.
                        "subjectEndsWith": "str",  # Optional. Extensions of input files.
                        "systemTopicResourceId": "str"  # Optional. ResourceId for System
                          Topic.
                    },
                    "statusModel": {
                        "code": "str",  # Status code. Required.
                        "message": "str"  # Optional. Message.
                    },
                    "storageModel": {
                        "blobStorageEndpoint": "str",  # The Uri of the blob storage account
                          in the form of 'https://:code:`<accountname>`.blob.core.windows.net'.
                          Required.
                        "errorOutputContainerName": "str",  # The name of the container that
                          saves the error messages during processing. Required.
                        "inputContainerName": "str",  # The name of the container that holds
                          the audio files to be processed. Required.
                        "outputContainerName": "str",  # The name of the container that
                          stores the transcription and analytics results. Required.
                        "processedContainerName": "str"  # The name of the container that
                          archives the audio files that have been transcribed. Required.
                    },
                    "analyticsModel": {
                        "endpoint": "str"  # The analytics endpoint to call. Required.
                    }
                }
        """

    @overload
    def create_or_replace_registration(
        self, name: str, resource: IO[bytes], *, content_type: str = "application/json", **kwargs: Any
    ) -> _models.Registration:
        # pylint: disable=line-too-long
        """Creates or replaces a Registration.

        :param name: The unique name of the registration resource. Required.
        :type name: str
        :param resource: The resource instance. Required.
        :type resource: IO[bytes]
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: Registration. The Registration is compatible with MutableMapping
        :rtype: ~speechingestion.models.Registration
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # response body for status code(s): 201, 200
                response == {
                    "batchTranscriptionModel": {
                        "customDomain": "str",  # Custom domain name for batch transcription.
                          Required.
                        "locale": "str",  # Optional. The expected locale of the audio data
                          to transcribe. For example, 'en-US', 'fr-FR', 'zh-CN', etc. For a full list
                          of supported locales, see `Supported languages and regions
                          <https://learn.microsoft.com/azure/ai-services/speech-service/language-support?tabs=stt>`_.
                        "modelX": {
                            "self": "str"  # self. Required.
                        },
                        "transcriptionProperties": {
                            "channels": [
                                0  # Optional. An array of channel numbers to
                                  process. Channels 0 and 1 are transcribed by default.
                            ],
                            "diarization": {
                                "speakers": {
                                    "maxCount": 0,  # Optional. Maximum count of
                                      speakers.
                                    "minCount": 0  # Optional. Minimum count of
                                      speakers.
                                }
                            },
                            "diarizationEnabled": bool,  # Optional. Specifies that the
                              Speech service should attempt diarization analysis on the input, which is
                              expected to be a mono channel that contains two voices. The default value
                              is false.
                            "displayFormWordLevelTimestampsEnabled": bool,  # Optional.
                              Specifies whether to include word-level timestamps on the display form of
                              the transcription results. The results are returned in the displayWords
                              property of the transcription file. The default value is false.
                            "languageIdentification": {
                                "candidateLocales": [
                                    "str"  # candidateLocales. Required.
                                ],
                                "mode": "str",  # mode. Required.
                                "speechModelMapping": {
                                    "str": {
                                        "self": "str"  # self. Required.
                                    }
                                }
                            },
                            "profanityFilterMode": "str",  # Optional. Specifies how to
                              handle profanity in recognition results. Accepted values are None to
                              disable profanity filtering, Masked to replace profanity with asterisks,
                              Removed to remove all profanity from the result, or Tags to add profanity
                              tags. The default value is Masked.
                            "punctuationMode": "str",  # Optional. Specifies how to
                              handle punctuation in recognition results. Accepted values are None to
                              disable punctuation, Dictated to imply explicit (spoken) punctuation,
                              Automatic to let the decoder deal with punctuation, or
                              DictatedAndAutomatic to use dictated and automatic punctuation. The
                              default value is DictatedAndAutomatic.
                            "wordLevelTimestampsEnabled": bool  # Optional. Specifies if
                              word level timestamps should be included in the output. The default value
                              is false.
                        }
                    },
                    "name": "str",  # The unique name of the registration resource. Required.
                    "processingModel": {
                        "deliveryMode": "str",  # deliveryMode. Required.
                        "subjectEndsWith": "str",  # Optional. Extensions of input files.
                        "systemTopicResourceId": "str"  # Optional. ResourceId for System
                          Topic.
                    },
                    "statusModel": {
                        "code": "str",  # Status code. Required.
                        "message": "str"  # Optional. Message.
                    },
                    "storageModel": {
                        "blobStorageEndpoint": "str",  # The Uri of the blob storage account
                          in the form of 'https://:code:`<accountname>`.blob.core.windows.net'.
                          Required.
                        "errorOutputContainerName": "str",  # The name of the container that
                          saves the error messages during processing. Required.
                        "inputContainerName": "str",  # The name of the container that holds
                          the audio files to be processed. Required.
                        "outputContainerName": "str",  # The name of the container that
                          stores the transcription and analytics results. Required.
                        "processedContainerName": "str"  # The name of the container that
                          archives the audio files that have been transcribed. Required.
                    },
                    "analyticsModel": {
                        "endpoint": "str"  # The analytics endpoint to call. Required.
                    }
                }
        """

    @distributed_trace
    def create_or_replace_registration(
        self, name: str, resource: Union[_models.Registration, JSON, IO[bytes]], **kwargs: Any
    ) -> _models.Registration:
        # pylint: disable=line-too-long
        """Creates or replaces a Registration.

        :param name: The unique name of the registration resource. Required.
        :type name: str
        :param resource: The resource instance. Is one of the following types: Registration, JSON,
         IO[bytes] Required.
        :type resource: ~speechingestion.models.Registration or JSON or IO[bytes]
        :return: Registration. The Registration is compatible with MutableMapping
        :rtype: ~speechingestion.models.Registration
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # JSON input template you can fill out and use as your body input.
                resource = {
                    "batchTranscriptionModel": {
                        "customDomain": "str",  # Custom domain name for batch transcription.
                          Required.
                        "locale": "str",  # Optional. The expected locale of the audio data
                          to transcribe. For example, 'en-US', 'fr-FR', 'zh-CN', etc. For a full list
                          of supported locales, see `Supported languages and regions
                          <https://learn.microsoft.com/azure/ai-services/speech-service/language-support?tabs=stt>`_.
                        "modelX": {
                            "self": "str"  # self. Required.
                        },
                        "transcriptionProperties": {
                            "channels": [
                                0  # Optional. An array of channel numbers to
                                  process. Channels 0 and 1 are transcribed by default.
                            ],
                            "diarization": {
                                "speakers": {
                                    "maxCount": 0,  # Optional. Maximum count of
                                      speakers.
                                    "minCount": 0  # Optional. Minimum count of
                                      speakers.
                                }
                            },
                            "diarizationEnabled": bool,  # Optional. Specifies that the
                              Speech service should attempt diarization analysis on the input, which is
                              expected to be a mono channel that contains two voices. The default value
                              is false.
                            "displayFormWordLevelTimestampsEnabled": bool,  # Optional.
                              Specifies whether to include word-level timestamps on the display form of
                              the transcription results. The results are returned in the displayWords
                              property of the transcription file. The default value is false.
                            "languageIdentification": {
                                "candidateLocales": [
                                    "str"  # candidateLocales. Required.
                                ],
                                "mode": "str",  # mode. Required.
                                "speechModelMapping": {
                                    "str": {
                                        "self": "str"  # self. Required.
                                    }
                                }
                            },
                            "profanityFilterMode": "str",  # Optional. Specifies how to
                              handle profanity in recognition results. Accepted values are None to
                              disable profanity filtering, Masked to replace profanity with asterisks,
                              Removed to remove all profanity from the result, or Tags to add profanity
                              tags. The default value is Masked.
                            "punctuationMode": "str",  # Optional. Specifies how to
                              handle punctuation in recognition results. Accepted values are None to
                              disable punctuation, Dictated to imply explicit (spoken) punctuation,
                              Automatic to let the decoder deal with punctuation, or
                              DictatedAndAutomatic to use dictated and automatic punctuation. The
                              default value is DictatedAndAutomatic.
                            "wordLevelTimestampsEnabled": bool  # Optional. Specifies if
                              word level timestamps should be included in the output. The default value
                              is false.
                        }
                    },
                    "name": "str",  # The unique name of the registration resource. Required.
                    "processingModel": {
                        "deliveryMode": "str",  # deliveryMode. Required.
                        "subjectEndsWith": "str",  # Optional. Extensions of input files.
                        "systemTopicResourceId": "str"  # Optional. ResourceId for System
                          Topic.
                    },
                    "statusModel": {
                        "code": "str",  # Status code. Required.
                        "message": "str"  # Optional. Message.
                    },
                    "storageModel": {
                        "blobStorageEndpoint": "str",  # The Uri of the blob storage account
                          in the form of 'https://:code:`<accountname>`.blob.core.windows.net'.
                          Required.
                        "errorOutputContainerName": "str",  # The name of the container that
                          saves the error messages during processing. Required.
                        "inputContainerName": "str",  # The name of the container that holds
                          the audio files to be processed. Required.
                        "outputContainerName": "str",  # The name of the container that
                          stores the transcription and analytics results. Required.
                        "processedContainerName": "str"  # The name of the container that
                          archives the audio files that have been transcribed. Required.
                    },
                    "analyticsModel": {
                        "endpoint": "str"  # The analytics endpoint to call. Required.
                    }
                }

                # response body for status code(s): 201, 200
                response == {
                    "batchTranscriptionModel": {
                        "customDomain": "str",  # Custom domain name for batch transcription.
                          Required.
                        "locale": "str",  # Optional. The expected locale of the audio data
                          to transcribe. For example, 'en-US', 'fr-FR', 'zh-CN', etc. For a full list
                          of supported locales, see `Supported languages and regions
                          <https://learn.microsoft.com/azure/ai-services/speech-service/language-support?tabs=stt>`_.
                        "modelX": {
                            "self": "str"  # self. Required.
                        },
                        "transcriptionProperties": {
                            "channels": [
                                0  # Optional. An array of channel numbers to
                                  process. Channels 0 and 1 are transcribed by default.
                            ],
                            "diarization": {
                                "speakers": {
                                    "maxCount": 0,  # Optional. Maximum count of
                                      speakers.
                                    "minCount": 0  # Optional. Minimum count of
                                      speakers.
                                }
                            },
                            "diarizationEnabled": bool,  # Optional. Specifies that the
                              Speech service should attempt diarization analysis on the input, which is
                              expected to be a mono channel that contains two voices. The default value
                              is false.
                            "displayFormWordLevelTimestampsEnabled": bool,  # Optional.
                              Specifies whether to include word-level timestamps on the display form of
                              the transcription results. The results are returned in the displayWords
                              property of the transcription file. The default value is false.
                            "languageIdentification": {
                                "candidateLocales": [
                                    "str"  # candidateLocales. Required.
                                ],
                                "mode": "str",  # mode. Required.
                                "speechModelMapping": {
                                    "str": {
                                        "self": "str"  # self. Required.
                                    }
                                }
                            },
                            "profanityFilterMode": "str",  # Optional. Specifies how to
                              handle profanity in recognition results. Accepted values are None to
                              disable profanity filtering, Masked to replace profanity with asterisks,
                              Removed to remove all profanity from the result, or Tags to add profanity
                              tags. The default value is Masked.
                            "punctuationMode": "str",  # Optional. Specifies how to
                              handle punctuation in recognition results. Accepted values are None to
                              disable punctuation, Dictated to imply explicit (spoken) punctuation,
                              Automatic to let the decoder deal with punctuation, or
                              DictatedAndAutomatic to use dictated and automatic punctuation. The
                              default value is DictatedAndAutomatic.
                            "wordLevelTimestampsEnabled": bool  # Optional. Specifies if
                              word level timestamps should be included in the output. The default value
                              is false.
                        }
                    },
                    "name": "str",  # The unique name of the registration resource. Required.
                    "processingModel": {
                        "deliveryMode": "str",  # deliveryMode. Required.
                        "subjectEndsWith": "str",  # Optional. Extensions of input files.
                        "systemTopicResourceId": "str"  # Optional. ResourceId for System
                          Topic.
                    },
                    "statusModel": {
                        "code": "str",  # Status code. Required.
                        "message": "str"  # Optional. Message.
                    },
                    "storageModel": {
                        "blobStorageEndpoint": "str",  # The Uri of the blob storage account
                          in the form of 'https://:code:`<accountname>`.blob.core.windows.net'.
                          Required.
                        "errorOutputContainerName": "str",  # The name of the container that
                          saves the error messages during processing. Required.
                        "inputContainerName": "str",  # The name of the container that holds
                          the audio files to be processed. Required.
                        "outputContainerName": "str",  # The name of the container that
                          stores the transcription and analytics results. Required.
                        "processedContainerName": "str"  # The name of the container that
                          archives the audio files that have been transcribed. Required.
                    },
                    "analyticsModel": {
                        "endpoint": "str"  # The analytics endpoint to call. Required.
                    }
                }
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models.Registration] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _content = None
        if isinstance(resource, (IOBase, bytes)):
            _content = resource
        else:
            _content = json.dumps(resource, cls=SdkJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_registrations_create_or_replace_registration_request(
            name=name,
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        _request.url = self._client.format_url(_request.url)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200, 201]:
            if _stream:
                response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if response.status_code == 200:
            if _stream:
                deserialized = response.iter_bytes()
            else:
                deserialized = _deserialize(_models.Registration, response.json())

        if response.status_code == 201:
            if _stream:
                deserialized = response.iter_bytes()
            else:
                deserialized = _deserialize(_models.Registration, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def delete_registration(self, name: str, **kwargs: Any) -> None:  # pylint: disable=inconsistent-return-statements
        """Delete a Registration.

        :param name: The unique name of the registration resource. Required.
        :type name: str
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        _request = build_registrations_delete_registration_request(
            name=name,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        _request.url = self._client.format_url(_request.url)

        _stream = False
        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [204]:
            if _stream:
                response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if cls:
            return cls(pipeline_response, None, {})  # type: ignore

    @distributed_trace
    def list_registrations(self, **kwargs: Any) -> Iterable["_models.Registration"]:
        # pylint: disable=line-too-long
        """List Registration resources.

        :return: An iterator like instance of Registration
        :rtype: ~azure.core.paging.ItemPaged[~speechingestion.models.Registration]
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # response body for status code(s): 200
                response == {
                    "batchTranscriptionModel": {
                        "customDomain": "str",  # Custom domain name for batch transcription.
                          Required.
                        "locale": "str",  # Optional. The expected locale of the audio data
                          to transcribe. For example, 'en-US', 'fr-FR', 'zh-CN', etc. For a full list
                          of supported locales, see `Supported languages and regions
                          <https://learn.microsoft.com/azure/ai-services/speech-service/language-support?tabs=stt>`_.
                        "modelX": {
                            "self": "str"  # self. Required.
                        },
                        "transcriptionProperties": {
                            "channels": [
                                0  # Optional. An array of channel numbers to
                                  process. Channels 0 and 1 are transcribed by default.
                            ],
                            "diarization": {
                                "speakers": {
                                    "maxCount": 0,  # Optional. Maximum count of
                                      speakers.
                                    "minCount": 0  # Optional. Minimum count of
                                      speakers.
                                }
                            },
                            "diarizationEnabled": bool,  # Optional. Specifies that the
                              Speech service should attempt diarization analysis on the input, which is
                              expected to be a mono channel that contains two voices. The default value
                              is false.
                            "displayFormWordLevelTimestampsEnabled": bool,  # Optional.
                              Specifies whether to include word-level timestamps on the display form of
                              the transcription results. The results are returned in the displayWords
                              property of the transcription file. The default value is false.
                            "languageIdentification": {
                                "candidateLocales": [
                                    "str"  # candidateLocales. Required.
                                ],
                                "mode": "str",  # mode. Required.
                                "speechModelMapping": {
                                    "str": {
                                        "self": "str"  # self. Required.
                                    }
                                }
                            },
                            "profanityFilterMode": "str",  # Optional. Specifies how to
                              handle profanity in recognition results. Accepted values are None to
                              disable profanity filtering, Masked to replace profanity with asterisks,
                              Removed to remove all profanity from the result, or Tags to add profanity
                              tags. The default value is Masked.
                            "punctuationMode": "str",  # Optional. Specifies how to
                              handle punctuation in recognition results. Accepted values are None to
                              disable punctuation, Dictated to imply explicit (spoken) punctuation,
                              Automatic to let the decoder deal with punctuation, or
                              DictatedAndAutomatic to use dictated and automatic punctuation. The
                              default value is DictatedAndAutomatic.
                            "wordLevelTimestampsEnabled": bool  # Optional. Specifies if
                              word level timestamps should be included in the output. The default value
                              is false.
                        }
                    },
                    "name": "str",  # The unique name of the registration resource. Required.
                    "processingModel": {
                        "deliveryMode": "str",  # deliveryMode. Required.
                        "subjectEndsWith": "str",  # Optional. Extensions of input files.
                        "systemTopicResourceId": "str"  # Optional. ResourceId for System
                          Topic.
                    },
                    "statusModel": {
                        "code": "str",  # Status code. Required.
                        "message": "str"  # Optional. Message.
                    },
                    "storageModel": {
                        "blobStorageEndpoint": "str",  # The Uri of the blob storage account
                          in the form of 'https://:code:`<accountname>`.blob.core.windows.net'.
                          Required.
                        "errorOutputContainerName": "str",  # The name of the container that
                          saves the error messages during processing. Required.
                        "inputContainerName": "str",  # The name of the container that holds
                          the audio files to be processed. Required.
                        "outputContainerName": "str",  # The name of the container that
                          stores the transcription and analytics results. Required.
                        "processedContainerName": "str"  # The name of the container that
                          archives the audio files that have been transcribed. Required.
                    },
                    "analyticsModel": {
                        "endpoint": "str"  # The analytics endpoint to call. Required.
                    }
                }
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[List[_models.Registration]] = kwargs.pop("cls", None)

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                _request = build_registrations_list_registrations_request(
                    api_version=self._config.api_version,
                    headers=_headers,
                    params=_params,
                )
                _request.url = self._client.format_url(_request.url)

            else:
                # make call to next link with the client's api-version
                _parsed_next_link = urllib.parse.urlparse(next_link)
                _next_request_params = case_insensitive_dict(
                    {
                        key: [urllib.parse.quote(v) for v in value]
                        for key, value in urllib.parse.parse_qs(_parsed_next_link.query).items()
                    }
                )
                _next_request_params["api-version"] = self._config.api_version
                _request = HttpRequest(
                    "GET", urllib.parse.urljoin(next_link, _parsed_next_link.path), params=_next_request_params
                )
                _request.url = self._client.format_url(_request.url)

            return _request

        def extract_data(pipeline_response):
            deserialized = pipeline_response.http_response.json()
            list_of_elem = _deserialize(List[_models.Registration], deserialized["value"])
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.get("nextLink") or None, iter(list_of_elem)

        def get_next(next_link=None):
            _request = prepare_request(next_link)

            _stream = False
            pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
                _request, stream=_stream, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                if _stream:
                    response.read()  # Load the body in memory and close the socket
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                raise HttpResponseError(response=response)

            return pipeline_response

        return ItemPaged(get_next, extract_data)
