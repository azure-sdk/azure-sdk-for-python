# pylint: disable=too-many-lines
# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) Python Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------
from io import IOBase
import json
import sys
from typing import Any, Callable, Dict, IO, List, Optional, TypeVar, Union, overload

from azure.core.exceptions import (
    ClientAuthenticationError,
    HttpResponseError,
    ResourceExistsError,
    ResourceNotFoundError,
    ResourceNotModifiedError,
    map_error,
)
from azure.core.pipeline import PipelineResponse
from azure.core.rest import AsyncHttpResponse, HttpRequest
from azure.core.tracing.decorator_async import distributed_trace_async
from azure.core.utils import case_insensitive_dict

from ... import models as _models
from ..._model_base import AzureJSONEncoder, _deserialize
from ..._operations._operations import (
    build_image_analysis_analyze_stream_request,
    build_image_analysis_analyze_url_request,
)
from .._vendor import ImageAnalysisClientMixinABC

if sys.version_info >= (3, 9):
    from collections.abc import MutableMapping
else:
    from typing import MutableMapping  # type: ignore  # pylint: disable=ungrouped-imports
if sys.version_info >= (3, 8):
    from typing import Literal  # pylint: disable=no-name-in-module, ungrouped-imports
else:
    from typing_extensions import Literal  # type: ignore  # pylint: disable=ungrouped-imports
JSON = MutableMapping[str, Any]  # pylint: disable=unsubscriptable-object
T = TypeVar("T")
ClsType = Optional[Callable[[PipelineResponse[HttpRequest, AsyncHttpResponse], T, Dict[str, Any]], Any]]


class ImageAnalysisClientOperationsMixin(ImageAnalysisClientMixinABC):
    @distributed_trace_async
    async def analyze_stream(
        self,
        image_contents: bytes,
        *,
        visual_features: Optional[List[Union[str, _models.visualFeatures]]] = None,
        model_name: Optional[str] = None,
        language: Optional[str] = None,
        smart_crops_aspect_ratios: Optional[str] = None,
        gender_neutral_caption: Optional[bool] = None,
        **kwargs: Any
    ) -> _models.ImageAnalysisResult:
        """Performs a single Image Analysis operation.

        :param image_contents: The image to be analyzed. Required.
        :type image_contents: bytes
        :keyword visual_features: A string indicating what visual feature types to return. Multiple
         values should be comma-separated. Valid visual feature types include: Categories, Tags,
         Description, Faces, ImageType, Color, Adult, Brands, Objects, and Celebrities. If
         VisualFeatures is not specified, then Categories, Tags, and Description are included in the
         response by default. Default value is None.
        :paramtype visual_features: list[str or ~azure.ai.vision.imageanalysis.models.visualFeatures]
        :keyword model_name: The name of the custom trained model. This parameter needs to be specified
         if the parameter "features" is not specified. Default value is None.
        :paramtype model_name: str
        :keyword language: The desired language for output generation. If this parameter is not
         specified, the default value is "en". See https://aka.ms/cv-languages for a list of supported
         languages. Default value is None.
        :paramtype language: str
        :keyword smart_crops_aspect_ratios: A list of aspect ratios to use for smartCrops feature.
         Aspect ratios are calculated by dividing the target crop width by the height. Supported values
         are between 0.75 and 1.8 (inclusive). Multiple values should be comma-separated. If this
         parameter is not specified, the service will return one crop suggestion with an aspect ratio it
         sees fit between 0.5 and 2.0 (inclusive). Default value is None.
        :paramtype smart_crops_aspect_ratios: str
        :keyword gender_neutral_caption: Boolean flag for enabling gender-neutral captioning for
         caption and denseCaptions features. If this parameter is not specified, the default value is
         "false". Default value is None.
        :paramtype gender_neutral_caption: bool
        :keyword overload: Impl Detail. Default value is "stream". Note that overriding this default
         value may result in unsupported behavior.
        :paramtype overload: str
        :keyword content_type: Impl Detail. Default value is "application/octet-stream".
        :paramtype content_type: str
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: ImageAnalysisResult. The ImageAnalysisResult is compatible with MutableMapping
        :rtype: ~azure.ai.vision.imageanalysis.models.ImageAnalysisResult
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

        overload: Literal["stream"] = kwargs.pop("overload", _params.pop("overload", "stream"))
        content_type: str = kwargs.pop("content_type", _headers.pop("Content-Type", "application/octet-stream"))
        cls: ClsType[_models.ImageAnalysisResult] = kwargs.pop("cls", None)

        _content = json.dumps(image_contents, cls=AzureJSONEncoder, exclude_readonly=True)  # type: ignore

        request = build_image_analysis_analyze_stream_request(
            visual_features=visual_features,
            model_name=model_name,
            language=language,
            smart_crops_aspect_ratios=smart_crops_aspect_ratios,
            gender_neutral_caption=gender_neutral_caption,
            content_type=content_type,
            overload=overload,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models.ImageAnalysisResult, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @overload
    async def analyze_url(
        self,
        image_contents: _models.ImageUrl,
        *,
        content_type: str = "application/json",
        visual_features: Optional[List[Union[str, _models.visualFeatures]]] = None,
        model_name: Optional[str] = None,
        language: Optional[str] = None,
        smart_crops_aspect_ratios: Optional[str] = None,
        gender_neutral_caption: Optional[bool] = None,
        **kwargs: Any
    ) -> _models.ImageAnalysisResult:
        """Performs a single Image Analysis operation.

        :param image_contents: The image to be analyzed. Required.
        :type image_contents: ~azure.ai.vision.imageanalysis.models.ImageUrl
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :keyword visual_features: A string indicating what visual feature types to return. Multiple
         values should be comma-separated. Valid visual feature types include: Categories, Tags,
         Description, Faces, ImageType, Color, Adult, Brands, Objects, and Celebrities. If
         VisualFeatures is not specified, then Categories, Tags, and Description are included in the
         response by default. Default value is None.
        :paramtype visual_features: list[str or ~azure.ai.vision.imageanalysis.models.visualFeatures]
        :keyword model_name: The name of the custom trained model. This parameter needs to be specified
         if the parameter "features" is not specified. Default value is None.
        :paramtype model_name: str
        :keyword language: The desired language for output generation. If this parameter is not
         specified, the default value is "en". See https://aka.ms/cv-languages for a list of supported
         languages. Default value is None.
        :paramtype language: str
        :keyword smart_crops_aspect_ratios: A list of aspect ratios to use for smartCrops feature.
         Aspect ratios are calculated by dividing the target crop width by the height. Supported values
         are between 0.75 and 1.8 (inclusive). Multiple values should be comma-separated. If this
         parameter is not specified, the service will return one crop suggestion with an aspect ratio it
         sees fit between 0.5 and 2.0 (inclusive). Default value is None.
        :paramtype smart_crops_aspect_ratios: str
        :keyword gender_neutral_caption: Boolean flag for enabling gender-neutral captioning for
         caption and denseCaptions features. If this parameter is not specified, the default value is
         "false". Default value is None.
        :paramtype gender_neutral_caption: bool
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: ImageAnalysisResult. The ImageAnalysisResult is compatible with MutableMapping
        :rtype: ~azure.ai.vision.imageanalysis.models.ImageAnalysisResult
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    async def analyze_url(
        self,
        image_contents: JSON,
        *,
        content_type: str = "application/json",
        visual_features: Optional[List[Union[str, _models.visualFeatures]]] = None,
        model_name: Optional[str] = None,
        language: Optional[str] = None,
        smart_crops_aspect_ratios: Optional[str] = None,
        gender_neutral_caption: Optional[bool] = None,
        **kwargs: Any
    ) -> _models.ImageAnalysisResult:
        """Performs a single Image Analysis operation.

        :param image_contents: The image to be analyzed. Required.
        :type image_contents: JSON
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :keyword visual_features: A string indicating what visual feature types to return. Multiple
         values should be comma-separated. Valid visual feature types include: Categories, Tags,
         Description, Faces, ImageType, Color, Adult, Brands, Objects, and Celebrities. If
         VisualFeatures is not specified, then Categories, Tags, and Description are included in the
         response by default. Default value is None.
        :paramtype visual_features: list[str or ~azure.ai.vision.imageanalysis.models.visualFeatures]
        :keyword model_name: The name of the custom trained model. This parameter needs to be specified
         if the parameter "features" is not specified. Default value is None.
        :paramtype model_name: str
        :keyword language: The desired language for output generation. If this parameter is not
         specified, the default value is "en". See https://aka.ms/cv-languages for a list of supported
         languages. Default value is None.
        :paramtype language: str
        :keyword smart_crops_aspect_ratios: A list of aspect ratios to use for smartCrops feature.
         Aspect ratios are calculated by dividing the target crop width by the height. Supported values
         are between 0.75 and 1.8 (inclusive). Multiple values should be comma-separated. If this
         parameter is not specified, the service will return one crop suggestion with an aspect ratio it
         sees fit between 0.5 and 2.0 (inclusive). Default value is None.
        :paramtype smart_crops_aspect_ratios: str
        :keyword gender_neutral_caption: Boolean flag for enabling gender-neutral captioning for
         caption and denseCaptions features. If this parameter is not specified, the default value is
         "false". Default value is None.
        :paramtype gender_neutral_caption: bool
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: ImageAnalysisResult. The ImageAnalysisResult is compatible with MutableMapping
        :rtype: ~azure.ai.vision.imageanalysis.models.ImageAnalysisResult
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    async def analyze_url(
        self,
        image_contents: IO,
        *,
        content_type: str = "application/json",
        visual_features: Optional[List[Union[str, _models.visualFeatures]]] = None,
        model_name: Optional[str] = None,
        language: Optional[str] = None,
        smart_crops_aspect_ratios: Optional[str] = None,
        gender_neutral_caption: Optional[bool] = None,
        **kwargs: Any
    ) -> _models.ImageAnalysisResult:
        """Performs a single Image Analysis operation.

        :param image_contents: The image to be analyzed. Required.
        :type image_contents: IO
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :keyword visual_features: A string indicating what visual feature types to return. Multiple
         values should be comma-separated. Valid visual feature types include: Categories, Tags,
         Description, Faces, ImageType, Color, Adult, Brands, Objects, and Celebrities. If
         VisualFeatures is not specified, then Categories, Tags, and Description are included in the
         response by default. Default value is None.
        :paramtype visual_features: list[str or ~azure.ai.vision.imageanalysis.models.visualFeatures]
        :keyword model_name: The name of the custom trained model. This parameter needs to be specified
         if the parameter "features" is not specified. Default value is None.
        :paramtype model_name: str
        :keyword language: The desired language for output generation. If this parameter is not
         specified, the default value is "en". See https://aka.ms/cv-languages for a list of supported
         languages. Default value is None.
        :paramtype language: str
        :keyword smart_crops_aspect_ratios: A list of aspect ratios to use for smartCrops feature.
         Aspect ratios are calculated by dividing the target crop width by the height. Supported values
         are between 0.75 and 1.8 (inclusive). Multiple values should be comma-separated. If this
         parameter is not specified, the service will return one crop suggestion with an aspect ratio it
         sees fit between 0.5 and 2.0 (inclusive). Default value is None.
        :paramtype smart_crops_aspect_ratios: str
        :keyword gender_neutral_caption: Boolean flag for enabling gender-neutral captioning for
         caption and denseCaptions features. If this parameter is not specified, the default value is
         "false". Default value is None.
        :paramtype gender_neutral_caption: bool
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: ImageAnalysisResult. The ImageAnalysisResult is compatible with MutableMapping
        :rtype: ~azure.ai.vision.imageanalysis.models.ImageAnalysisResult
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace_async
    async def analyze_url(
        self,
        image_contents: Union[_models.ImageUrl, JSON, IO],
        *,
        visual_features: Optional[List[Union[str, _models.visualFeatures]]] = None,
        model_name: Optional[str] = None,
        language: Optional[str] = None,
        smart_crops_aspect_ratios: Optional[str] = None,
        gender_neutral_caption: Optional[bool] = None,
        **kwargs: Any
    ) -> _models.ImageAnalysisResult:
        """Performs a single Image Analysis operation.

        :param image_contents: The image to be analyzed. Is one of the following types: ImageUrl, JSON,
         IO Required.
        :type image_contents: ~azure.ai.vision.imageanalysis.models.ImageUrl or JSON or IO
        :keyword visual_features: A string indicating what visual feature types to return. Multiple
         values should be comma-separated. Valid visual feature types include: Categories, Tags,
         Description, Faces, ImageType, Color, Adult, Brands, Objects, and Celebrities. If
         VisualFeatures is not specified, then Categories, Tags, and Description are included in the
         response by default. Default value is None.
        :paramtype visual_features: list[str or ~azure.ai.vision.imageanalysis.models.visualFeatures]
        :keyword model_name: The name of the custom trained model. This parameter needs to be specified
         if the parameter "features" is not specified. Default value is None.
        :paramtype model_name: str
        :keyword language: The desired language for output generation. If this parameter is not
         specified, the default value is "en". See https://aka.ms/cv-languages for a list of supported
         languages. Default value is None.
        :paramtype language: str
        :keyword smart_crops_aspect_ratios: A list of aspect ratios to use for smartCrops feature.
         Aspect ratios are calculated by dividing the target crop width by the height. Supported values
         are between 0.75 and 1.8 (inclusive). Multiple values should be comma-separated. If this
         parameter is not specified, the service will return one crop suggestion with an aspect ratio it
         sees fit between 0.5 and 2.0 (inclusive). Default value is None.
        :paramtype smart_crops_aspect_ratios: str
        :keyword gender_neutral_caption: Boolean flag for enabling gender-neutral captioning for
         caption and denseCaptions features. If this parameter is not specified, the default value is
         "false". Default value is None.
        :paramtype gender_neutral_caption: bool
        :keyword content_type: Impl Detail. Default value is None.
        :paramtype content_type: str
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: ImageAnalysisResult. The ImageAnalysisResult is compatible with MutableMapping
        :rtype: ~azure.ai.vision.imageanalysis.models.ImageAnalysisResult
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models.ImageAnalysisResult] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _content = None
        if isinstance(image_contents, (IOBase, bytes)):
            _content = image_contents
        else:
            _content = json.dumps(image_contents, cls=AzureJSONEncoder, exclude_readonly=True)  # type: ignore

        request = build_image_analysis_analyze_url_request(
            visual_features=visual_features,
            model_name=model_name,
            language=language,
            smart_crops_aspect_ratios=smart_crops_aspect_ratios,
            gender_neutral_caption=gender_neutral_caption,
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models.ImageAnalysisResult, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore
