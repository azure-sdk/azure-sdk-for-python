# pylint: disable=too-many-lines,too-many-statements
# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) Python Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------
from io import IOBase
import json
import sys
from typing import Any, Callable, Dict, IO, Optional, Type, TypeVar, Union, overload

from azure.core.exceptions import (
    ClientAuthenticationError,
    HttpResponseError,
    ResourceExistsError,
    ResourceNotFoundError,
    ResourceNotModifiedError,
    map_error,
)
from azure.core.pipeline import PipelineResponse
from azure.core.rest import AsyncHttpResponse, HttpRequest
from azure.core.tracing.decorator_async import distributed_trace_async
from azure.core.utils import case_insensitive_dict

from ... import models as _models
from ..._model_base import SdkJSONEncoder, _deserialize
from ...operations._operations import build_chat_create_request, build_chat_create_streaming_request

if sys.version_info >= (3, 9):
    from collections.abc import MutableMapping
else:
    from typing import MutableMapping  # type: ignore  # pylint: disable=ungrouped-imports
JSON = MutableMapping[str, Any]  # pylint: disable=unsubscriptable-object
T = TypeVar("T")
ClsType = Optional[Callable[[PipelineResponse[HttpRequest, AsyncHttpResponse], T, Dict[str, Any]], Any]]


class ChatOperations:
    """
    .. warning::
        **DO NOT** instantiate this class directly.

        Instead, you should access the following operations through
        :class:`~azure.ai.chatprotocol.aio.ChatProtocolClient`'s
        :attr:`chat` attribute.
    """

    def __init__(self, *args, **kwargs) -> None:
        input_args = list(args)
        self._client = input_args.pop(0) if input_args else kwargs.pop("client")
        self._config = input_args.pop(0) if input_args else kwargs.pop("config")
        self._serialize = input_args.pop(0) if input_args else kwargs.pop("serializer")
        self._deserialize = input_args.pop(0) if input_args else kwargs.pop("deserializer")

    @overload
    async def create_streaming(
        self,
        operation_route: str,
        body: _models.StreamingChatCompletionOptions,
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _models.ChatCompletionChunk:
        # pylint: disable=line-too-long
        """Creates a new streaming chat completion.

        :param operation_route: The route where the endpoint exposes the chat operations. Required.
        :type operation_route: str
        :param body: Required.
        :type body: ~azure.ai.chatprotocol.models.StreamingChatCompletionOptions
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: ChatCompletionChunk. The ChatCompletionChunk is compatible with MutableMapping
        :rtype: ~azure.ai.chatprotocol.models.ChatCompletionChunk
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # JSON input template you can fill out and use as your body input.
                body = {
                    "messages": [
                        chat_message
                    ],
                    "stream": True,  # Default value is True. Indicates whether the completion is
                      a streaming or non-streaming completion. Required.
                    "context": {
                        "str": {}  # Optional. Context allows the chat app to receive extra
                          parameters from the client, such as temperature, functions, or customer_info.
                          These parameters are specific to the chat app and not understood by the
                          generic clients.
                    },
                    "sessionState": {}  # Optional. Field that allows the chat app to store and
                      retrieve data, the structure of such data is dependant on the backend being used.
                      The client must send back the data in this field unchanged in subsequent
                      requests, until the chat app sends a new one. The data in this field can be used
                      to implement stateful services, such as remembering previous conversations or
                      user preferences.
                }

                # response body for status code(s): 200
                response == {
                    "choices": [
                        {
                            "delta": chat_message_delta,
                            "index": 0,  # The index of the of the chat choice, relative
                              to the other choices in the same completion. Required.
                            "context": {
                                "str": {}  # Optional. Context allows the chat app to
                                  receive extra parameters from the client, such as temperature,
                                  functions, or customer_info. These parameters are specific to the
                                  chat app and not understood by the generic clients.
                            },
                            "finishReason": "str",  # Optional. The reason this chat
                              completion completed its generation. Known values are: "stop" and
                              "length".
                            "sessionState": {}  # Optional. Field that allows the chat
                              app to store and retrieve data, the structure of such data is dependant
                              on the backend being used. The client must send back the data in this
                              field unchanged in subsequent requests, until the chat app sends a new
                              one. The data in this field can be used to implement stateful services,
                              such as remembering previous conversations or user preferences.
                        }
                    ]
                }
        """

    @overload
    async def create_streaming(
        self, operation_route: str, body: JSON, *, content_type: str = "application/json", **kwargs: Any
    ) -> _models.ChatCompletionChunk:
        # pylint: disable=line-too-long
        """Creates a new streaming chat completion.

        :param operation_route: The route where the endpoint exposes the chat operations. Required.
        :type operation_route: str
        :param body: Required.
        :type body: JSON
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: ChatCompletionChunk. The ChatCompletionChunk is compatible with MutableMapping
        :rtype: ~azure.ai.chatprotocol.models.ChatCompletionChunk
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # response body for status code(s): 200
                response == {
                    "choices": [
                        {
                            "delta": chat_message_delta,
                            "index": 0,  # The index of the of the chat choice, relative
                              to the other choices in the same completion. Required.
                            "context": {
                                "str": {}  # Optional. Context allows the chat app to
                                  receive extra parameters from the client, such as temperature,
                                  functions, or customer_info. These parameters are specific to the
                                  chat app and not understood by the generic clients.
                            },
                            "finishReason": "str",  # Optional. The reason this chat
                              completion completed its generation. Known values are: "stop" and
                              "length".
                            "sessionState": {}  # Optional. Field that allows the chat
                              app to store and retrieve data, the structure of such data is dependant
                              on the backend being used. The client must send back the data in this
                              field unchanged in subsequent requests, until the chat app sends a new
                              one. The data in this field can be used to implement stateful services,
                              such as remembering previous conversations or user preferences.
                        }
                    ]
                }
        """

    @overload
    async def create_streaming(
        self, operation_route: str, body: IO[bytes], *, content_type: str = "application/json", **kwargs: Any
    ) -> _models.ChatCompletionChunk:
        # pylint: disable=line-too-long
        """Creates a new streaming chat completion.

        :param operation_route: The route where the endpoint exposes the chat operations. Required.
        :type operation_route: str
        :param body: Required.
        :type body: IO[bytes]
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: ChatCompletionChunk. The ChatCompletionChunk is compatible with MutableMapping
        :rtype: ~azure.ai.chatprotocol.models.ChatCompletionChunk
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # response body for status code(s): 200
                response == {
                    "choices": [
                        {
                            "delta": chat_message_delta,
                            "index": 0,  # The index of the of the chat choice, relative
                              to the other choices in the same completion. Required.
                            "context": {
                                "str": {}  # Optional. Context allows the chat app to
                                  receive extra parameters from the client, such as temperature,
                                  functions, or customer_info. These parameters are specific to the
                                  chat app and not understood by the generic clients.
                            },
                            "finishReason": "str",  # Optional. The reason this chat
                              completion completed its generation. Known values are: "stop" and
                              "length".
                            "sessionState": {}  # Optional. Field that allows the chat
                              app to store and retrieve data, the structure of such data is dependant
                              on the backend being used. The client must send back the data in this
                              field unchanged in subsequent requests, until the chat app sends a new
                              one. The data in this field can be used to implement stateful services,
                              such as remembering previous conversations or user preferences.
                        }
                    ]
                }
        """

    @distributed_trace_async
    async def create_streaming(
        self, operation_route: str, body: Union[_models.StreamingChatCompletionOptions, JSON, IO[bytes]], **kwargs: Any
    ) -> _models.ChatCompletionChunk:
        # pylint: disable=line-too-long
        """Creates a new streaming chat completion.

        :param operation_route: The route where the endpoint exposes the chat operations. Required.
        :type operation_route: str
        :param body: Is one of the following types: StreamingChatCompletionOptions, JSON, IO[bytes]
         Required.
        :type body: ~azure.ai.chatprotocol.models.StreamingChatCompletionOptions or JSON or IO[bytes]
        :return: ChatCompletionChunk. The ChatCompletionChunk is compatible with MutableMapping
        :rtype: ~azure.ai.chatprotocol.models.ChatCompletionChunk
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # JSON input template you can fill out and use as your body input.
                body = {
                    "messages": [
                        chat_message
                    ],
                    "stream": True,  # Default value is True. Indicates whether the completion is
                      a streaming or non-streaming completion. Required.
                    "context": {
                        "str": {}  # Optional. Context allows the chat app to receive extra
                          parameters from the client, such as temperature, functions, or customer_info.
                          These parameters are specific to the chat app and not understood by the
                          generic clients.
                    },
                    "sessionState": {}  # Optional. Field that allows the chat app to store and
                      retrieve data, the structure of such data is dependant on the backend being used.
                      The client must send back the data in this field unchanged in subsequent
                      requests, until the chat app sends a new one. The data in this field can be used
                      to implement stateful services, such as remembering previous conversations or
                      user preferences.
                }

                # response body for status code(s): 200
                response == {
                    "choices": [
                        {
                            "delta": chat_message_delta,
                            "index": 0,  # The index of the of the chat choice, relative
                              to the other choices in the same completion. Required.
                            "context": {
                                "str": {}  # Optional. Context allows the chat app to
                                  receive extra parameters from the client, such as temperature,
                                  functions, or customer_info. These parameters are specific to the
                                  chat app and not understood by the generic clients.
                            },
                            "finishReason": "str",  # Optional. The reason this chat
                              completion completed its generation. Known values are: "stop" and
                              "length".
                            "sessionState": {}  # Optional. Field that allows the chat
                              app to store and retrieve data, the structure of such data is dependant
                              on the backend being used. The client must send back the data in this
                              field unchanged in subsequent requests, until the chat app sends a new
                              one. The data in this field can be used to implement stateful services,
                              such as remembering previous conversations or user preferences.
                        }
                    ]
                }
        """
        error_map: MutableMapping[int, Type[HttpResponseError]] = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models.ChatCompletionChunk] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _content = None
        if isinstance(body, (IOBase, bytes)):
            _content = body
        else:
            _content = json.dumps(body, cls=SdkJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_chat_create_streaming_request(
            operation_route=operation_route,
            content_type=content_type,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str"),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models.ChatCompletionChunk, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @overload
    async def create(
        self,
        operation_route: str,
        body: _models.ChatCompletionOptions,
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _models.ChatCompletion:
        # pylint: disable=line-too-long
        """Creates a new chat completion.

        :param operation_route: The route where the endpoint exposes the chat operations. Required.
        :type operation_route: str
        :param body: Required.
        :type body: ~azure.ai.chatprotocol.models.ChatCompletionOptions
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: ChatCompletion. The ChatCompletion is compatible with MutableMapping
        :rtype: ~azure.ai.chatprotocol.models.ChatCompletion
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # JSON input template you can fill out and use as your body input.
                body = {
                    "messages": [
                        chat_message
                    ],
                    "stream": False,  # Default value is False. Indicates whether the completion
                      is a streaming or non-streaming completion. Required.
                    "context": {
                        "str": {}  # Optional. Context allows the chat app to receive extra
                          parameters from the client, such as temperature, functions, or customer_info.
                          These parameters are specific to the chat app and not understood by the
                          generic clients.
                    },
                    "sessionState": {}  # Optional. Field that allows the chat app to store and
                      retrieve data, the structure of such data is dependant on the backend being used.
                      The client must send back the data in this field unchanged in subsequent
                      requests, until the chat app sends a new one. The data in this field can be used
                      to implement stateful services, such as remembering previous conversations or
                      user preferences.
                }

                # response body for status code(s): 200
                response == {
                    "choices": [
                        {
                            "finishReason": "str",  # The reason this chat completion
                              completed its generation. Required. Known values are: "stop" and
                              "length".
                            "index": 0,  # The index of the of the chat choice, relative
                              to the other choices in the same completion. Required.
                            "message": chat_message,
                            "context": {
                                "str": {}  # Optional. Context allows the chat app to
                                  receive extra parameters from the client, such as temperature,
                                  functions, or customer_info. These parameters are specific to the
                                  chat app and not understood by the generic clients.
                            },
                            "sessionState": {}  # Optional. Field that allows the chat
                              app to store and retrieve data, the structure of such data is dependant
                              on the backend being used. The client must send back the data in this
                              field unchanged in subsequent requests, until the chat app sends a new
                              one. The data in this field can be used to implement stateful services,
                              such as remembering previous conversations or user preferences.
                        }
                    ]
                }
        """

    @overload
    async def create(
        self, operation_route: str, body: JSON, *, content_type: str = "application/json", **kwargs: Any
    ) -> _models.ChatCompletion:
        # pylint: disable=line-too-long
        """Creates a new chat completion.

        :param operation_route: The route where the endpoint exposes the chat operations. Required.
        :type operation_route: str
        :param body: Required.
        :type body: JSON
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: ChatCompletion. The ChatCompletion is compatible with MutableMapping
        :rtype: ~azure.ai.chatprotocol.models.ChatCompletion
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # response body for status code(s): 200
                response == {
                    "choices": [
                        {
                            "finishReason": "str",  # The reason this chat completion
                              completed its generation. Required. Known values are: "stop" and
                              "length".
                            "index": 0,  # The index of the of the chat choice, relative
                              to the other choices in the same completion. Required.
                            "message": chat_message,
                            "context": {
                                "str": {}  # Optional. Context allows the chat app to
                                  receive extra parameters from the client, such as temperature,
                                  functions, or customer_info. These parameters are specific to the
                                  chat app and not understood by the generic clients.
                            },
                            "sessionState": {}  # Optional. Field that allows the chat
                              app to store and retrieve data, the structure of such data is dependant
                              on the backend being used. The client must send back the data in this
                              field unchanged in subsequent requests, until the chat app sends a new
                              one. The data in this field can be used to implement stateful services,
                              such as remembering previous conversations or user preferences.
                        }
                    ]
                }
        """

    @overload
    async def create(
        self, operation_route: str, body: IO[bytes], *, content_type: str = "application/json", **kwargs: Any
    ) -> _models.ChatCompletion:
        # pylint: disable=line-too-long
        """Creates a new chat completion.

        :param operation_route: The route where the endpoint exposes the chat operations. Required.
        :type operation_route: str
        :param body: Required.
        :type body: IO[bytes]
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: ChatCompletion. The ChatCompletion is compatible with MutableMapping
        :rtype: ~azure.ai.chatprotocol.models.ChatCompletion
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # response body for status code(s): 200
                response == {
                    "choices": [
                        {
                            "finishReason": "str",  # The reason this chat completion
                              completed its generation. Required. Known values are: "stop" and
                              "length".
                            "index": 0,  # The index of the of the chat choice, relative
                              to the other choices in the same completion. Required.
                            "message": chat_message,
                            "context": {
                                "str": {}  # Optional. Context allows the chat app to
                                  receive extra parameters from the client, such as temperature,
                                  functions, or customer_info. These parameters are specific to the
                                  chat app and not understood by the generic clients.
                            },
                            "sessionState": {}  # Optional. Field that allows the chat
                              app to store and retrieve data, the structure of such data is dependant
                              on the backend being used. The client must send back the data in this
                              field unchanged in subsequent requests, until the chat app sends a new
                              one. The data in this field can be used to implement stateful services,
                              such as remembering previous conversations or user preferences.
                        }
                    ]
                }
        """

    @distributed_trace_async
    async def create(
        self, operation_route: str, body: Union[_models.ChatCompletionOptions, JSON, IO[bytes]], **kwargs: Any
    ) -> _models.ChatCompletion:
        # pylint: disable=line-too-long
        """Creates a new chat completion.

        :param operation_route: The route where the endpoint exposes the chat operations. Required.
        :type operation_route: str
        :param body: Is one of the following types: ChatCompletionOptions, JSON, IO[bytes] Required.
        :type body: ~azure.ai.chatprotocol.models.ChatCompletionOptions or JSON or IO[bytes]
        :return: ChatCompletion. The ChatCompletion is compatible with MutableMapping
        :rtype: ~azure.ai.chatprotocol.models.ChatCompletion
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # JSON input template you can fill out and use as your body input.
                body = {
                    "messages": [
                        chat_message
                    ],
                    "stream": False,  # Default value is False. Indicates whether the completion
                      is a streaming or non-streaming completion. Required.
                    "context": {
                        "str": {}  # Optional. Context allows the chat app to receive extra
                          parameters from the client, such as temperature, functions, or customer_info.
                          These parameters are specific to the chat app and not understood by the
                          generic clients.
                    },
                    "sessionState": {}  # Optional. Field that allows the chat app to store and
                      retrieve data, the structure of such data is dependant on the backend being used.
                      The client must send back the data in this field unchanged in subsequent
                      requests, until the chat app sends a new one. The data in this field can be used
                      to implement stateful services, such as remembering previous conversations or
                      user preferences.
                }

                # response body for status code(s): 200
                response == {
                    "choices": [
                        {
                            "finishReason": "str",  # The reason this chat completion
                              completed its generation. Required. Known values are: "stop" and
                              "length".
                            "index": 0,  # The index of the of the chat choice, relative
                              to the other choices in the same completion. Required.
                            "message": chat_message,
                            "context": {
                                "str": {}  # Optional. Context allows the chat app to
                                  receive extra parameters from the client, such as temperature,
                                  functions, or customer_info. These parameters are specific to the
                                  chat app and not understood by the generic clients.
                            },
                            "sessionState": {}  # Optional. Field that allows the chat
                              app to store and retrieve data, the structure of such data is dependant
                              on the backend being used. The client must send back the data in this
                              field unchanged in subsequent requests, until the chat app sends a new
                              one. The data in this field can be used to implement stateful services,
                              such as remembering previous conversations or user preferences.
                        }
                    ]
                }
        """
        error_map: MutableMapping[int, Type[HttpResponseError]] = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models.ChatCompletion] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _content = None
        if isinstance(body, (IOBase, bytes)):
            _content = body
        else:
            _content = json.dumps(body, cls=SdkJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_chat_create_request(
            operation_route=operation_route,
            content_type=content_type,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str"),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models.ChatCompletion, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore
