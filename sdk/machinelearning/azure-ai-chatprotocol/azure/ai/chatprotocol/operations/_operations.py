# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) Python Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------
from io import IOBase
import json
import sys
from typing import Any, Callable, Dict, IO, List, Literal, Optional, TypeVar, Union, overload

from azure.core import PipelineClient
from azure.core.exceptions import (
    ClientAuthenticationError,
    HttpResponseError,
    ResourceExistsError,
    ResourceNotFoundError,
    ResourceNotModifiedError,
    StreamClosedError,
    StreamConsumedError,
    map_error,
)
from azure.core.pipeline import PipelineResponse
from azure.core.rest import HttpRequest, HttpResponse
from azure.core.tracing.decorator import distributed_trace
from azure.core.utils import case_insensitive_dict

from .. import models as _models
from .._configuration import ChatProtocolClientConfiguration
from .._model_base import SdkJSONEncoder, _deserialize
from .._serialization import Deserializer, Serializer

if sys.version_info >= (3, 9):
    from collections.abc import MutableMapping
else:
    from typing import MutableMapping  # type: ignore
JSON = MutableMapping[str, Any]  # pylint: disable=unsubscriptable-object
_Unset: Any = object()
T = TypeVar("T")
ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]

_SERIALIZER = Serializer()
_SERIALIZER.client_side_validation = False


def build_chat_create_streaming_request(operation_route: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/{operationRoute}"
    path_format_arguments = {
        "operationRoute": _SERIALIZER.url("operation_route", operation_route, "str"),
    }

    _url: str = _url.format(**path_format_arguments)  # type: ignore

    # Construct headers
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, headers=_headers, **kwargs)


def build_chat_create_request(operation_route: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/{operationRoute}"
    path_format_arguments = {
        "operationRoute": _SERIALIZER.url("operation_route", operation_route, "str"),
    }

    _url: str = _url.format(**path_format_arguments)  # type: ignore

    # Construct headers
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, headers=_headers, **kwargs)


class ChatOperations:
    """
    .. warning::
        **DO NOT** instantiate this class directly.

        Instead, you should access the following operations through
        :class:`~azure.ai.chatprotocol.ChatProtocolClient`'s
        :attr:`chat` attribute.
    """

    def __init__(self, *args, **kwargs):
        input_args = list(args)
        self._client: PipelineClient = input_args.pop(0) if input_args else kwargs.pop("client")
        self._config: ChatProtocolClientConfiguration = input_args.pop(0) if input_args else kwargs.pop("config")
        self._serialize: Serializer = input_args.pop(0) if input_args else kwargs.pop("serializer")
        self._deserialize: Deserializer = input_args.pop(0) if input_args else kwargs.pop("deserializer")

    @overload
    def create_streaming(
        self,
        operation_route: str,
        *,
        messages: List[_models.ChatMessage],
        stream_parameter: Literal[True],
        content_type: str = "application/json",
        session_state: Optional[Any] = None,
        context: Optional[Dict[str, Any]] = None,
        **kwargs: Any
    ) -> _models.ChatCompletionChunk:
        """Creates a new streaming chat completion.

        :param operation_route: The route where the endpoint exposes the chat operations. Required.
        :type operation_route: str
        :keyword messages: The collection of context messages associated with this completion request.
         Required.
        :paramtype messages: list[~azure.ai.chatprotocol.models.ChatMessage]
        :keyword stream_parameter: Indicates whether the completion is a streaming or non-streaming
         completion. Required. Note that overriding this default value may result in unsupported
         behavior.
        :paramtype stream_parameter: bool
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :keyword session_state: Field that allows the chat app to store and retrieve data, the
         structure of such data is dependant on the backend
         being used. The client must send back the data in this field unchanged in subsequent requests,
         until the chat app
         sends a new one. The data in this field can be used to implement stateful services, such as
         remembering previous
         conversations or user preferences. Default value is None.
        :paramtype session_state: any
        :keyword context: Context allows the chat app to receive extra parameters from the client, such
         as temperature, functions, or
         customer_info. These parameters are specific to the chat app and not understood by the generic
         clients. Default value is None.
        :paramtype context: dict[str, any]
        :return: ChatCompletionChunk. The ChatCompletionChunk is compatible with MutableMapping
        :rtype: ~azure.ai.chatprotocol.models.ChatCompletionChunk
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def create_streaming(
        self, operation_route: str, body: JSON, *, content_type: str = "application/json", **kwargs: Any
    ) -> _models.ChatCompletionChunk:
        """Creates a new streaming chat completion.

        :param operation_route: The route where the endpoint exposes the chat operations. Required.
        :type operation_route: str
        :param body: Required.
        :type body: JSON
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: ChatCompletionChunk. The ChatCompletionChunk is compatible with MutableMapping
        :rtype: ~azure.ai.chatprotocol.models.ChatCompletionChunk
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def create_streaming(
        self, operation_route: str, body: IO[bytes], *, content_type: str = "application/json", **kwargs: Any
    ) -> _models.ChatCompletionChunk:
        """Creates a new streaming chat completion.

        :param operation_route: The route where the endpoint exposes the chat operations. Required.
        :type operation_route: str
        :param body: Required.
        :type body: IO[bytes]
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: ChatCompletionChunk. The ChatCompletionChunk is compatible with MutableMapping
        :rtype: ~azure.ai.chatprotocol.models.ChatCompletionChunk
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def create_streaming(
        self,
        operation_route: str,
        body: Union[JSON, IO[bytes]] = _Unset,
        *,
        messages: List[_models.ChatMessage] = _Unset,
        stream_parameter: Literal[True] = _Unset,
        session_state: Optional[Any] = None,
        context: Optional[Dict[str, Any]] = None,
        **kwargs: Any
    ) -> _models.ChatCompletionChunk:
        """Creates a new streaming chat completion.

        :param operation_route: The route where the endpoint exposes the chat operations. Required.
        :type operation_route: str
        :param body: Is either a JSON type or a IO[bytes] type. Required.
        :type body: JSON or IO[bytes]
        :keyword messages: The collection of context messages associated with this completion request.
         Required.
        :paramtype messages: list[~azure.ai.chatprotocol.models.ChatMessage]
        :keyword stream_parameter: Indicates whether the completion is a streaming or non-streaming
         completion. Required. Note that overriding this default value may result in unsupported
         behavior.
        :paramtype stream_parameter: bool
        :keyword session_state: Field that allows the chat app to store and retrieve data, the
         structure of such data is dependant on the backend
         being used. The client must send back the data in this field unchanged in subsequent requests,
         until the chat app
         sends a new one. The data in this field can be used to implement stateful services, such as
         remembering previous
         conversations or user preferences. Default value is None.
        :paramtype session_state: any
        :keyword context: Context allows the chat app to receive extra parameters from the client, such
         as temperature, functions, or
         customer_info. These parameters are specific to the chat app and not understood by the generic
         clients. Default value is None.
        :paramtype context: dict[str, any]
        :return: ChatCompletionChunk. The ChatCompletionChunk is compatible with MutableMapping
        :rtype: ~azure.ai.chatprotocol.models.ChatCompletionChunk
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models.ChatCompletionChunk] = kwargs.pop("cls", None)

        if body is _Unset:
            if messages is _Unset:
                raise TypeError("missing required argument: messages")
            if stream_parameter is _Unset:
                raise TypeError("missing required argument: stream_parameter")
            body = {"context": context, "messages": messages, "sessionState": session_state, "stream": stream_parameter}
            body = {k: v for k, v in body.items() if v is not None}
        content_type = content_type or "application/json"
        _content = None
        if isinstance(body, (IOBase, bytes)):
            _content = body
        else:
            _content = json.dumps(body, cls=SdkJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_chat_create_streaming_request(
            operation_route=operation_route,
            content_type=content_type,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str"),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                try:
                    response.read()  # Load the body in memory and close the socket
                except (StreamConsumedError, StreamClosedError):
                    pass
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models.ChatCompletionChunk, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @overload
    def create(
        self,
        operation_route: str,
        *,
        messages: List[_models.ChatMessage],
        stream_parameter: Literal[False],
        content_type: str = "application/json",
        session_state: Optional[Any] = None,
        context: Optional[Dict[str, Any]] = None,
        **kwargs: Any
    ) -> _models.ChatCompletion:
        """Creates a new chat completion.

        :param operation_route: The route where the endpoint exposes the chat operations. Required.
        :type operation_route: str
        :keyword messages: The collection of context messages associated with this completion request.
         Required.
        :paramtype messages: list[~azure.ai.chatprotocol.models.ChatMessage]
        :keyword stream_parameter: Indicates whether the completion is a streaming or non-streaming
         completion. Required. Note that overriding this default value may result in unsupported
         behavior.
        :paramtype stream_parameter: bool
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :keyword session_state: Field that allows the chat app to store and retrieve data, the
         structure of such data is dependant on the backend
         being used. The client must send back the data in this field unchanged in subsequent requests,
         until the chat app
         sends a new one. The data in this field can be used to implement stateful services, such as
         remembering previous
         conversations or user preferences. Default value is None.
        :paramtype session_state: any
        :keyword context: Context allows the chat app to receive extra parameters from the client, such
         as temperature, functions, or
         customer_info. These parameters are specific to the chat app and not understood by the generic
         clients. Default value is None.
        :paramtype context: dict[str, any]
        :return: ChatCompletion. The ChatCompletion is compatible with MutableMapping
        :rtype: ~azure.ai.chatprotocol.models.ChatCompletion
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def create(
        self, operation_route: str, body: JSON, *, content_type: str = "application/json", **kwargs: Any
    ) -> _models.ChatCompletion:
        """Creates a new chat completion.

        :param operation_route: The route where the endpoint exposes the chat operations. Required.
        :type operation_route: str
        :param body: Required.
        :type body: JSON
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: ChatCompletion. The ChatCompletion is compatible with MutableMapping
        :rtype: ~azure.ai.chatprotocol.models.ChatCompletion
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def create(
        self, operation_route: str, body: IO[bytes], *, content_type: str = "application/json", **kwargs: Any
    ) -> _models.ChatCompletion:
        """Creates a new chat completion.

        :param operation_route: The route where the endpoint exposes the chat operations. Required.
        :type operation_route: str
        :param body: Required.
        :type body: IO[bytes]
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: ChatCompletion. The ChatCompletion is compatible with MutableMapping
        :rtype: ~azure.ai.chatprotocol.models.ChatCompletion
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def create(
        self,
        operation_route: str,
        body: Union[JSON, IO[bytes]] = _Unset,
        *,
        messages: List[_models.ChatMessage] = _Unset,
        stream_parameter: Literal[False] = _Unset,
        session_state: Optional[Any] = None,
        context: Optional[Dict[str, Any]] = None,
        **kwargs: Any
    ) -> _models.ChatCompletion:
        """Creates a new chat completion.

        :param operation_route: The route where the endpoint exposes the chat operations. Required.
        :type operation_route: str
        :param body: Is either a JSON type or a IO[bytes] type. Required.
        :type body: JSON or IO[bytes]
        :keyword messages: The collection of context messages associated with this completion request.
         Required.
        :paramtype messages: list[~azure.ai.chatprotocol.models.ChatMessage]
        :keyword stream_parameter: Indicates whether the completion is a streaming or non-streaming
         completion. Required. Note that overriding this default value may result in unsupported
         behavior.
        :paramtype stream_parameter: bool
        :keyword session_state: Field that allows the chat app to store and retrieve data, the
         structure of such data is dependant on the backend
         being used. The client must send back the data in this field unchanged in subsequent requests,
         until the chat app
         sends a new one. The data in this field can be used to implement stateful services, such as
         remembering previous
         conversations or user preferences. Default value is None.
        :paramtype session_state: any
        :keyword context: Context allows the chat app to receive extra parameters from the client, such
         as temperature, functions, or
         customer_info. These parameters are specific to the chat app and not understood by the generic
         clients. Default value is None.
        :paramtype context: dict[str, any]
        :return: ChatCompletion. The ChatCompletion is compatible with MutableMapping
        :rtype: ~azure.ai.chatprotocol.models.ChatCompletion
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models.ChatCompletion] = kwargs.pop("cls", None)

        if body is _Unset:
            if messages is _Unset:
                raise TypeError("missing required argument: messages")
            if stream_parameter is _Unset:
                raise TypeError("missing required argument: stream_parameter")
            body = {"context": context, "messages": messages, "sessionState": session_state, "stream": stream_parameter}
            body = {k: v for k, v in body.items() if v is not None}
        content_type = content_type or "application/json"
        _content = None
        if isinstance(body, (IOBase, bytes)):
            _content = body
        else:
            _content = json.dumps(body, cls=SdkJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_chat_create_request(
            operation_route=operation_route,
            content_type=content_type,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str"),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                try:
                    response.read()  # Load the body in memory and close the socket
                except (StreamConsumedError, StreamClosedError):
                    pass
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models.ChatCompletion, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore
